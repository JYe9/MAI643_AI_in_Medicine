{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAI643 - Artificial Intelligence in Medicine\n",
    "\n",
    "Project Assignment 1 - Spring Semester 2024\n",
    "\n",
    "Student Name:    \n",
    "Christina Ioanna Saroglaki   \n",
    "Jianlin Ye \n",
    "\n",
    "UCY Email:     \n",
    "saroglaki.christina-ioanna@ucy.ac.cy    \n",
    "jye00001@ucy.ac.cy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_factor_df = pd.read_csv(\"risk_factors_cervical_cancer.csv\")\n",
    "\n",
    "# Only keep the \"Biopsy\" column as the target variable\n",
    "risk_factor_df = risk_factor_df.drop(columns=[\"Hinselmann\",\"Schiller\",\"Citology\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranformed all the numeric values into  the correct numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_factor_df = risk_factor_df.apply(pd.to_numeric, errors = \"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset to features and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = risk_factor_df.iloc[:,:-4]\n",
    "dep_df = risk_factor_df.iloc[:,-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "We identified that the features “STDs: Time since first diagnosis” and “STDs: Time since last diagnosis” were filled with NaN values to about 92%. Because of the high percentage of missing values, it impractical to either eliminate those observations or fill the missing data with the mean of the existing data. Consequently, these features were excluded from the dataset for the development of the models.\n",
    "\n",
    "For the remaining columns, we replaced the missing values with the mean of the existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_factor_df = risk_factor_df.drop(columns=[\"STDs: Time since first diagnosis\", \"STDs: Time since last diagnosis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mean\n",
    "print(\"--------------------------- Filling Missing Values ---------------------------\")\n",
    "print(\"----------------------------------- BEFORE -----------------------------------\")\n",
    "print(\"Number of rows before filling missing values: \", len(risk_factor_df))\n",
    "\n",
    "# Display the number of missing values before filling\n",
    "print(\"\\nNumber of missing values per column before filling:\")\n",
    "print(risk_factor_df.isnull().sum())\n",
    "\n",
    "# Fill missing values with mean\n",
    "risk_factor_df.fillna(risk_factor_df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n----------------------------------- AFTER -----------------------------------\")\n",
    "print(\"Number of rows after filling missing values: \", len(risk_factor_df))\n",
    "\n",
    "# Display the number of missing values after filling\n",
    "print(\"\\nNumber of missing values per column after filling:\")\n",
    "print(risk_factor_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate Rows\n",
    "\n",
    "Removing duplicate rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate rows\n",
    "print(\"----------------------------- Removing Duplicates ----------------------------\")\n",
    "print(\"----------------------------------- BEFORE -----------------------------------\")\n",
    "print(\"Number of rows before removing duplicates: \", len(risk_factor_df))\n",
    "\n",
    "# Drop duplicate rows\n",
    "risk_factor_df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"----------------------------------- AFTER -----------------------------------\")\n",
    "print(\"Number of rows after removing duplicates: \", len(risk_factor_df))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
